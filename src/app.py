import streamlit as st
import pandas as pd
import joblib
import re
import nltk
import os
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# ==========================================
# 1. CONFIGURATION & RESSOURCES
# ==========================================
st.set_page_config(
    page_title="Phishing Detector AI",
    page_icon="üõ°Ô∏è",
    layout="centered"
)

# T√©l√©chargement silencieux des ressources NLTK
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)

# ==========================================
# 2. CLASSE & FONCTIONS (Identiques √† l'entra√Ænement)
# ==========================================
class EmailPreprocessor:
    def __init__(self):
        self.stop_words = set(stopwords.words("english"))
        self.lemmatizer = WordNetLemmatizer()

    def preprocess(self, text):
        if not isinstance(text, str): return ""
        text = text.lower()
        text = re.sub(r"http\S+|www\S+|https\S+", "", text)
        text = re.sub(r"[^a-z\s]", " ", text)
        text = re.sub(r"\s+", " ", text).strip()
        tokens = text.split()
        tokens = [self.lemmatizer.lemmatize(t) for t in tokens if t not in self.stop_words and len(t) > 2]
        return " ".join(tokens)

def extract_features_from_text(raw_text):
    """
    Transforme le texte brut coll√© par l'utilisateur en DataFrame
    avec les m√™mes colonnes que lors de l'entra√Ænement.
    """
    # 1. Extraction Header (Regex simple)
    def get_header(text, field):
        match = re.search(rf"{field}\s*:(.*)", text, re.IGNORECASE)
        return match.group(1).strip() if match else "unknown"

    # Tentative de s√©paration Header/Body
    try:
        parts = raw_text.split("\n\n", 1)
        body = parts[1] if len(parts) > 1 else raw_text
    except:
        body = raw_text

    subj = get_header(raw_text, "Subject")
    from_ = get_header(raw_text, "From")
    
    # 2. Features Statistiques
    suspicious_words = ["urgent", "verify", "account", "update", "bank", "suspend", "click", "password", "security", "login"]
    
    url_count = len(re.findall(r"http\S+|www\S+", raw_text))
    susp_word_count = sum(raw_text.lower().count(w) for w in suspicious_words)
    caps_ratio = sum(1 for c in raw_text if c.isupper()) / len(raw_text) if len(raw_text) > 0 else 0
    
    # 3. NLP
    preprocessor = EmailPreprocessor()
    message_combined = f"{subj} {body}"
    processed_body = preprocessor.preprocess(message_combined)

    # 4. DataFrame (Ordre des colonnes CRUCIAL)
    df = pd.DataFrame([{
        'processed_body': processed_body,
        'from_': from_,
        'subject': subj,
        'url_count': url_count,
        'susp_word_count': susp_word_count,
        'caps_ratio': caps_ratio
    }])
    
    return df

# ==========================================
# 3. INTERFACE STREAMLIT
# ==========================================
st.title("üõ°Ô∏è Phishing Email Detector")
st.markdown("Collez le contenu d'un email (avec les headers si possible) pour analyser s'il est malveillant.")

# Chargement du mod√®le avec chemin sp√©cifique
@st.cache_resource
def load_model():
    # Monte d'un dossier ‚Üí va dans /models
    base_dir = os.path.dirname(os.path.abspath(__file__))   # chemin vers src/
    model_path = os.path.join(base_dir, "..", "models", "best_phishing_model.pkl")
    model_path = os.path.abspath(model_path)

    if not os.path.exists(model_path):
        st.error(f"‚ùå Mod√®le introuvable : {model_path}")
        st.info("Assurez-vous que 'best_phishing_model.pkl' est dans /models.")
        return None

    try:
        return joblib.load(model_path)
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {e}")
        return None

model = load_model()

# Zone de texte
email_input = st.text_area("Contenu de l'email", height=300, placeholder="From: ...\nSubject: ...\n\nDear Customer...")

if st.button("üîç Analyser l'email"):
    if not email_input:
        st.warning("Veuillez coller un texte d'abord.")
    elif model:
        # Pr√©paration
        input_df = extract_features_from_text(email_input)
        
        # Pr√©diction
        prediction = model.predict(input_df)[0]
        
        # Affichage R√©sultat
        st.divider()
        col1, col2 = st.columns([1, 2])
        
        with col1:
            if prediction == 1:
                st.error("üö® PHISHING D√âTECT√â")
                # Ic√¥ne Warning
                st.markdown("## ‚ö†Ô∏è")
            else:
                st.success("‚úÖ EMAIL L√âGITIME")
                # Ic√¥ne Check
                st.markdown("## üõ°Ô∏è")
        
        with col2:
            st.subheader("D√©tails de l'analyse")
            st.write(f"**Sujet d√©tect√© :** {input_df['subject'][0]}")
            st.write(f"**Exp√©diteur :** {input_df['from_'][0]}")
            st.write(f"**Mots suspects trouv√©s :** {input_df['susp_word_count'][0]}")
            st.write(f"**Liens d√©tect√©s :** {input_df['url_count'][0]}")
            
            # Feature Importance (Si dispo)
            if prediction == 1:
                st.warning("‚ö†Ô∏è Cet email contient des indicateurs d'urgence et des liens suspects.")
            else:
                st.info("‚ÑπÔ∏è Le style et le vocabulaire correspondent √† une communication normale.")

st.markdown("---")
st.caption("D√©velopp√© par l'√©quipe Data Science - Mod√®le entra√Æn√© sur Enron & Phishing Corpus")
